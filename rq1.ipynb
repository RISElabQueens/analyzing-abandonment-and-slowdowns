{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)  \n",
    "pd.set_option('display.max_columns', None)   \n",
    "pd.set_option('display.width', None)         \n",
    "\n",
    "artifacts = pd.read_csv(\"artifacts.csv\")\n",
    "artifact_release = pd.read_csv(\"artifact_release.csv\")\n",
    "release = pd.read_csv(\"releases.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_release['artifact_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "release['release_timestamp'] = pd.to_datetime(release['release_timestamp'], unit='ms')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge artifacts with their releases\n",
    "artifact_releases = pd.merge(artifact_release, release, on='release_id', how='inner')\n",
    "artifact_releases = pd.merge(artifact_releases, artifacts[['artifact_id']], on='artifact_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the date range\n",
    "start_date = '2014-09-04'\n",
    "end_date = '2024-09-04'\n",
    "\n",
    "# Filter the release history to include only records within 2014-2024\n",
    "filtered_release_history = artifact_releases[\n",
    "    (artifact_releases['release_timestamp'] >= start_date) &\n",
    "    (artifact_releases['release_timestamp'] <= end_date)\n",
    "]\n",
    "filtered_release_history = filtered_release_history.sort_values(by=['artifact_id', 'release_timestamp'])\n",
    "filtered_release_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_release_history['artifact_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Group by artifact_id and get the first and last release date per project\n",
    "release_date_range = filtered_release_history.groupby('artifact_id')['release_timestamp'].agg(['min', 'max'])\n",
    "# Group by artifact_id and get the first and last release date per project\n",
    "release_date_range = filtered_release_history.groupby('artifact_id')['release_timestamp'].agg(['min', 'max'])\n",
    "\n",
    "# Filter to include only projects with both first and last release dates within 2014-2024\n",
    "valid_projects = release_date_range[\n",
    "    (release_date_range['min'] >= start_date) &\n",
    "    (release_date_range['max'] <= end_date)\n",
    "].index\n",
    "\n",
    "# Filter the original dataframe to include only valid projects\n",
    "filtered_release_history = filtered_release_history[filtered_release_history['artifact_id'].isin(valid_projects)]\n",
    "filtered_release_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_release_history['artifact_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_project_cutoff = pd.to_datetime('2023-08-30')\n",
    "\n",
    "\n",
    "# Group by artifact_id to get the first and last release dates and count of releases per project\n",
    "release_date_range = filtered_release_history.groupby('artifact_id')['release_timestamp'].agg(['min', 'max', 'count'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "release_date_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply filters:\n",
    "# 1. Include projects with more than 1 release\n",
    "# 2. Include projects with the first release date before August 30, 2023\n",
    "valid_projects = release_date_range[\n",
    "    (release_date_range['count'] > 1) &  # More than 1 release\n",
    "    (release_date_range['min'] < new_project_cutoff)  # First release before August 30, 2023\n",
    "].index\n",
    "\n",
    "valid_projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_release_history = filtered_release_history[filtered_release_history['artifact_id'].isin(valid_projects)]\n",
    "filtered_release_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_release_history['artifact_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtered_release_history.to_csv('full_release_history.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract year from release_timestamp\n",
    "filtered_release_history['release_year'] = filtered_release_history['release_timestamp'].dt.year\n",
    "\n",
    "# Define the abandonment cutoff date\n",
    "abandonment_cutoff = pd.to_datetime('2022-09-04')\n",
    "\n",
    "# Identify the last release date per project\n",
    "last_release_per_project = filtered_release_history.groupby('artifact_id')['release_timestamp'].max()\n",
    "\n",
    "# Identify abandoned projects (last release on or before the abandonment cutoff date)\n",
    "abandoned_projects = last_release_per_project[last_release_per_project <= abandonment_cutoff].index\n",
    "\n",
    "# Find the first release year for each project (artifact_id)\n",
    "first_release_year = (\n",
    "    filtered_release_history.groupby('artifact_id')['release_year']\n",
    "    .min()\n",
    "    .reset_index()\n",
    "    .rename(columns={'release_year': 'creation_year'})\n",
    ")\n",
    "\n",
    "# Filter for abandoned projects in the original dataframe to get their release history\n",
    "abandoned_release_history = filtered_release_history[filtered_release_history['artifact_id'].isin(abandoned_projects)]\n",
    "\n",
    "# Get the last release year for each abandoned project\n",
    "abandoned_projects_last_year = (\n",
    "    abandoned_release_history.groupby('artifact_id')['release_timestamp']\n",
    "    .max()\n",
    "    .dt.year\n",
    "    .reset_index()\n",
    "    .rename(columns={'release_timestamp': 'abandonment_year'})\n",
    ")\n",
    "\n",
    "# Initialize sets and list for cumulative tracking\n",
    "cumulative_projects = set()\n",
    "yearly_data = []\n",
    "\n",
    "# Iterate over years and calculate yearly data\n",
    "for year in sorted(filtered_release_history['release_year'].unique()):\n",
    "    # Projects created in the current year\n",
    "    new_projects = set(first_release_year[first_release_year['creation_year'] == year]['artifact_id'])\n",
    "    \n",
    "    # Continuing projects: Exclude projects abandoned in the previous year\n",
    "    if year > min(filtered_release_history['release_year'].unique()):  # Avoid looking for abandoned projects before the first year\n",
    "        abandoned_last_year = set(\n",
    "            abandoned_projects_last_year[abandoned_projects_last_year['abandonment_year'] == (year - 1)]['artifact_id']\n",
    "        )\n",
    "        cumulative_projects -= abandoned_last_year  # Remove abandoned projects from the cumulative set\n",
    "    \n",
    "    # Continuing projects: Projects in cumulative set not newly created this year\n",
    "    continuing_projects = cumulative_projects - new_projects\n",
    "    \n",
    "    # Add current year's new projects to the cumulative set\n",
    "    cumulative_projects.update(new_projects)\n",
    "    \n",
    "    # Total projects for the year (new + continuing)\n",
    "    total_projects = len(new_projects) + len(continuing_projects)\n",
    "    \n",
    "    # Update cumulative set for tracking unique projects\n",
    "    cumulative_unique_projects = len(cumulative_projects)\n",
    "    \n",
    "    # Append yearly data\n",
    "    yearly_data.append({\n",
    "        'year': year,\n",
    "        'continuing_projects': len(continuing_projects),\n",
    "        'new_projects': len(new_projects),\n",
    "        'total_projects_active': total_projects,\n",
    "        #'cumulative_unique_projects': cumulative_unique_projects\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "yearly_projects_df = pd.DataFrame(yearly_data)\n",
    "\n",
    "# Incorporate abandonment data\n",
    "abandoned_yearly_data = []\n",
    "cumulative_abandoned_projects = set()\n",
    "\n",
    "for year in sorted(filtered_release_history['release_year'].unique()):\n",
    "    # Abandoned projects in the current year\n",
    "    abandoned_in_year = set(\n",
    "        abandoned_projects_last_year[abandoned_projects_last_year['abandonment_year'] == year]['artifact_id']\n",
    "    )\n",
    "    # Update cumulative abandoned projects\n",
    "    cumulative_abandoned_projects.update(abandoned_in_year)\n",
    "    \n",
    "    # Append abandonment data\n",
    "    abandoned_yearly_data.append({\n",
    "        'year': year,\n",
    "        'total_unique_abandoned': len(abandoned_in_year),\n",
    "        'cumsum_total_unique_abandoned': len(cumulative_abandoned_projects)\n",
    "    })\n",
    "\n",
    "# Merge yearly abandonment data with the project data\n",
    "abandoned_yearly_df = pd.DataFrame(abandoned_yearly_data)\n",
    "yearly_projects_df = yearly_projects_df.merge(abandoned_yearly_df, on='year', how='left')\n",
    "\n",
    "# Fill NaNs with 0s for years without abandonment\n",
    "yearly_projects_df.fillna(0, inplace=True)\n",
    "\n",
    "# Convert counts to integers for clarity\n",
    "yearly_projects_df = yearly_projects_df.astype({\n",
    "    'continuing_projects': 'int',\n",
    "    'new_projects': 'int',\n",
    "    'total_projects_active': 'int',\n",
    "   # 'cumulative_unique_projects': 'int',\n",
    "    'total_unique_abandoned': 'int',\n",
    "    'cumsum_total_unique_abandoned': 'int'\n",
    "})\n",
    "\n",
    "# Display the updated DataFrame\n",
    "yearly_projects_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yearly_projects_df.to_latex('yearly_projects_df',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the abandonment rate as total_unique_abandoned / total_projects\n",
    "yearly_projects_df['abandonment_rate'] = yearly_projects_df['total_unique_abandoned'] / yearly_projects_df['total_projects_active']\n",
    "\n",
    "# Display the updated DataFrame\n",
    "yearly_projects_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate cumulative total projects\n",
    "yearly_projects_df['cumulative_total_projects'] = yearly_projects_df['total_projects_active'] + yearly_projects_df['cumsum_total_unique_abandoned']\n",
    "\n",
    "# Plot cumulative total projects vs abandoned projects\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(yearly_projects_df['year'], yearly_projects_df['cumulative_total_projects'], label='Cumulative total libraries', marker='o')\n",
    "plt.plot(yearly_projects_df['year'], yearly_projects_df['cumsum_total_unique_abandoned'], label='Cumulative abandoned libraries', marker='o')\n",
    "\n",
    "# Add labels, title, legend, and grid\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of projects')\n",
    "plt.title('Trend of Total (active+abandoned) and abandoned libraries over time')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify projects as abandoned or active\n",
    "# abandoned_projects = last_release_per_project[last_release_per_project <= abandonment_cutoff].index\n",
    "active_projects = last_release_per_project[last_release_per_project > abandonment_cutoff].index\n",
    "active_release_history = filtered_release_history[filtered_release_history['artifact_id'].isin(active_projects)]\n",
    "abandoned_release_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abandoned_release_history['artifact_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_release_history['artifact_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the last release date per project\n",
    "last_release_per_project = filtered_release_history.groupby('artifact_id')['release_timestamp'].max()\n",
    "last_release_per_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by artifact_id and release_timestamp to calculate intervals in both active and abandoned projects\n",
    "active_release_history = active_release_history.sort_values(by=['artifact_id', 'release_timestamp'])\n",
    "abandoned_release_history = abandoned_release_history.sort_values(by=['artifact_id', 'release_timestamp'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_release_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ensure release_timestamp is in datetime format\n",
    "abandoned_release_history['release_timestamp'] = pd.to_datetime(abandoned_release_history['release_timestamp'])\n",
    "\n",
    "# Step 1: Determine first and last release dates for each project (artifact)\n",
    "project_lifespans = (\n",
    "    abandoned_release_history\n",
    "    .sort_values('release_timestamp')\n",
    "    .groupby('artifact_id')\n",
    "    .agg(\n",
    "        first_release_date=('release_timestamp', 'first'),\n",
    "        last_release_date=('release_timestamp', 'last')\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Calculate lifespan in days\n",
    "project_lifespans['lifespan_days'] = (project_lifespans['last_release_date'] - project_lifespans['first_release_date']).dt.days\n",
    "\n",
    "# Step 2: Segment by cohort (initial release year)\n",
    "project_lifespans['cohort_year'] = project_lifespans['first_release_date'].dt.year\n",
    "\n",
    "# Step 3: Calculate mean and median lifespan by cohort\n",
    "cohort_lifespans = (\n",
    "    project_lifespans\n",
    "    .groupby('cohort_year')\n",
    "    .agg(\n",
    "        mean_lifespan_days=('lifespan_days', 'mean'),\n",
    "        median_lifespan_days=('lifespan_days', 'median'),\n",
    "        num_projects=('artifact_id', 'nunique')\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Display the results\n",
    "cohort_lifespans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Define the abandonment cutoff date\n",
    "abandonment_cutoff = pd.to_datetime('2022-09-04')\n",
    "\n",
    "# Determine if a project is abandoned\n",
    "project_lifespans['abandoned'] = project_lifespans['last_release_date'] <= abandonment_cutoff\n",
    "\n",
    "# Calculate the abandonment year\n",
    "project_lifespans['abandonment_year'] = np.where(\n",
    "    project_lifespans['abandoned'],\n",
    "    project_lifespans['last_release_date'].dt.year,\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "# Calculate the age at abandonment (years since first release)\n",
    "project_lifespans['years_to_abandonment'] = (\n",
    "    project_lifespans['abandonment_year'] - project_lifespans['cohort_year']\n",
    ")\n",
    "\n",
    "# Filter only the abandoned projects\n",
    "abandoned_projects = project_lifespans[project_lifespans['abandoned']].copy()\n",
    "\n",
    "# Summarize abandonment counts by cohort year and years to abandonment\n",
    "abandonment_summary = (\n",
    "    abandoned_projects\n",
    "    .groupby(['cohort_year', 'years_to_abandonment'])\n",
    "    .agg({'artifact_id': 'nunique'})\n",
    "    .reset_index()\n",
    "    .rename(columns={'artifact_id': 'num_abandoned_projects'})\n",
    ")\n",
    "\n",
    "# Display the abandonment summary\n",
    "abandonment_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Define the abandonment cutoff date\n",
    "abandonment_cutoff = pd.to_datetime('2022-09-04')\n",
    "\n",
    "# Determine if a project is abandoned\n",
    "project_lifespans['abandoned'] = project_lifespans['last_release_date'] <= abandonment_cutoff\n",
    "\n",
    "# Calculate the abandonment year\n",
    "project_lifespans['abandonment_year'] = np.where(\n",
    "    project_lifespans['abandoned'],\n",
    "    project_lifespans['last_release_date'].dt.year,\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "# Calculate the age at abandonment (years since first release)\n",
    "project_lifespans['years_to_abandonment'] = (\n",
    "    project_lifespans['abandonment_year'] - project_lifespans['cohort_year']\n",
    ")\n",
    "\n",
    "# Convert 'years_to_abandonment' to integer (and handle NaN)\n",
    "project_lifespans['years_to_abandonment'] = project_lifespans['years_to_abandonment'].fillna(-1).astype(int)\n",
    "\n",
    "# Filter only the abandoned projects\n",
    "abandoned_projects = project_lifespans[project_lifespans['abandoned']].copy()\n",
    "\n",
    "# Summarize abandonment counts by cohort year and years to abandonment\n",
    "abandonment_summary = (\n",
    "    abandoned_projects\n",
    "    .groupby(['cohort_year', 'years_to_abandonment'])\n",
    "    .agg(num_abandoned_projects=('artifact_id', 'nunique'))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Pivot the 'abandonment_summary' DataFrame to have 'years_to_abandonment' as columns\n",
    "abandonment_pivot = abandonment_summary.pivot(\n",
    "    index='cohort_year',\n",
    "    columns='years_to_abandonment',\n",
    "    values='num_abandoned_projects'\n",
    ").fillna(0)\n",
    "\n",
    "# Optional: Select the specific years you are interested in (e.g., 1, 2, 3, 5)\n",
    "milestones = [1, 2, 3]\n",
    "\n",
    "# Ensure all milestones are included in the columns (add missing ones with zero counts)\n",
    "for milestone in milestones:\n",
    "    if milestone not in abandonment_pivot.columns:\n",
    "        abandonment_pivot[milestone] = 0\n",
    "\n",
    "# Sort the columns for consistency\n",
    "abandonment_pivot = abandonment_pivot.sort_index(axis=1)\n",
    "\n",
    "# Rename the columns to reflect 'abandoned_after_X_years'\n",
    "abandonment_pivot.rename(columns={year: f'abandoned_after_{year}_years' for year in abandonment_pivot.columns}, inplace=True)\n",
    "\n",
    "# Reset index to turn 'cohort_year' back into a column\n",
    "abandonment_pivot.reset_index(inplace=True)\n",
    "\n",
    "# Display the abandonment pivot table\n",
    "abandonment_pivot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total number of projects per cohort\n",
    "total_projects = (\n",
    "    project_lifespans.groupby('cohort_year')['artifact_id']\n",
    "    .nunique()\n",
    "    .reset_index()\n",
    "    .rename(columns={'artifact_id': 'num_projects'})\n",
    ")\n",
    "\n",
    "# Merge total projects with the abandonment pivot table\n",
    "abandonment_pivot = abandonment_pivot.merge(total_projects, on='cohort_year', how='left')\n",
    "\n",
    "# Reorder columns to place 'num_projects' after 'cohort_year' for clarity\n",
    "cols = ['cohort_year', 'num_projects'] + [col for col in abandonment_pivot.columns if col not in ['cohort_year', 'num_projects']]\n",
    "abandonment_pivot = abandonment_pivot[cols]\n",
    "\n",
    "# Display the updated DataFrame\n",
    "abandonment_pivot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "upto this, we are only looking total number of abandoned projects per year. now to fair comparison and calculate the rates, adding the active projects below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assume 'abandoned_release_history' and 'active_release_history' DataFrames exist\n",
    "\n",
    "# Ensure release_timestamp is in datetime format for both datasets\n",
    "abandoned_release_history['release_timestamp'] = pd.to_datetime(abandoned_release_history['release_timestamp'])\n",
    "active_release_history['release_timestamp'] = pd.to_datetime(active_release_history['release_timestamp'])\n",
    "\n",
    "# Step 1: Determine first and last release dates for each project (artifact) in both datasets\n",
    "abandoned_project_lifespans = (\n",
    "    abandoned_release_history\n",
    "    .sort_values('release_timestamp')\n",
    "    .groupby('artifact_id')\n",
    "    .agg(\n",
    "        first_release_date=('release_timestamp', 'first'),\n",
    "        last_release_date=('release_timestamp', 'last')\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "active_project_lifespans = (\n",
    "    active_release_history\n",
    "    .sort_values('release_timestamp')\n",
    "    .groupby('artifact_id')\n",
    "    .agg(\n",
    "        first_release_date=('release_timestamp', 'first'),\n",
    "        last_release_date=('release_timestamp', 'last')\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Step 2: Combine both datasets into 'project_lifespans'\n",
    "project_lifespans = pd.concat([abandoned_project_lifespans, active_project_lifespans], ignore_index=True)\n",
    "\n",
    "# Step 3: Calculate lifespan in days\n",
    "project_lifespans['lifespan_days'] = (\n",
    "    project_lifespans['last_release_date'] - project_lifespans['first_release_date']\n",
    ").dt.days\n",
    "\n",
    "# Step 4: Segment by cohort (initial release year)\n",
    "project_lifespans['cohort_year'] = project_lifespans['first_release_date'].dt.year\n",
    "\n",
    "# Define the abandonment cutoff date\n",
    "abandonment_cutoff = pd.to_datetime('2022-09-04')\n",
    "\n",
    "# Step 5: Determine if a project is abandoned\n",
    "project_lifespans['abandoned'] = project_lifespans['last_release_date'] <= abandonment_cutoff\n",
    "\n",
    "# Step 6: Calculate the abandonment year\n",
    "project_lifespans['abandonment_year'] = np.where(\n",
    "    project_lifespans['abandoned'],\n",
    "    project_lifespans['last_release_date'].dt.year,\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "# Step 7: Calculate the age at abandonment or censoring (years since first release)\n",
    "project_lifespans['years_to_event'] = np.where(\n",
    "    project_lifespans['abandoned'],\n",
    "    project_lifespans['abandonment_year'] - project_lifespans['cohort_year'],\n",
    "    abandonment_cutoff.year - project_lifespans['cohort_year']\n",
    ")\n",
    "project_lifespans['years_to_event'] = project_lifespans['years_to_event'].astype(int)\n",
    "\n",
    "# Step 8: Create milestone columns to indicate abandonment by specific years\n",
    "milestones = [0, 1, 2, 3]\n",
    "\n",
    "for milestone in milestones:\n",
    "    project_lifespans[f'abandoned_by_{milestone}_years'] = np.where(\n",
    "        (project_lifespans['abandoned']) & (project_lifespans['years_to_event'] <= milestone),\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "\n",
    "# Step 9: Summarize abandonment counts by cohort year\n",
    "abandonment_summary = (\n",
    "    project_lifespans\n",
    "    .groupby('cohort_year')\n",
    "    .agg(\n",
    "        total_projects=('artifact_id', 'nunique'),\n",
    "        **{f'abandoned_by_{milestone}_years': (f'abandoned_by_{milestone}_years', 'sum') for milestone in milestones}\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Step 10: Calculate active projects remaining after each milestone\n",
    "for milestone in milestones:\n",
    "    abandonment_summary[f'active_after_{milestone}_years'] = (\n",
    "        abandonment_summary['total_projects'] - abandonment_summary[f'abandoned_by_{milestone}_years']\n",
    "    )\n",
    "\n",
    "# Optional: Reorder columns for clarity\n",
    "cols = ['cohort_year', 'total_projects'] + \\\n",
    "       sum([[f'abandoned_by_{milestone}_years', f'active_after_{milestone}_years'] for milestone in milestones], [])\n",
    "abandonment_summary = abandonment_summary[cols]\n",
    "\n",
    "# Step 11: Display the final DataFrame\n",
    "abandonment_summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total_abandoned_projects per cohort_year\n",
    "total_abandoned_projects = (\n",
    "    project_lifespans[project_lifespans['abandoned']]\n",
    "    .groupby('cohort_year')['artifact_id']\n",
    "    .nunique()\n",
    "    .reset_index()\n",
    "    .rename(columns={'artifact_id': 'total_abandoned_projects'})\n",
    ")\n",
    "\n",
    "# Merge total_abandoned_projects into abandonment_summary\n",
    "abandonment_summary = abandonment_summary.merge(total_abandoned_projects, on='cohort_year', how='left')\n",
    "\n",
    "# Fill NaN with zeros (in case some cohorts have no abandoned projects)\n",
    "abandonment_summary['total_abandoned_projects'] = abandonment_summary['total_abandoned_projects'].fillna(0).astype(int)\n",
    "\n",
    "# Calculate total_active_projects\n",
    "abandonment_summary['total_active_projects'] = (\n",
    "    abandonment_summary['total_projects'] - abandonment_summary['total_abandoned_projects']\n",
    ")\n",
    "\n",
    "# Reorder columns for clarity\n",
    "cols = ['cohort_year', 'total_projects', 'total_abandoned_projects', 'total_active_projects'] + \\\n",
    "       [col for col in abandonment_summary.columns if col not in ['cohort_year', 'total_projects', 'total_abandoned_projects', 'total_active_projects']]\n",
    "abandonment_summary = abandonment_summary[cols]\n",
    "\n",
    "# Display the final DataFrame\n",
    "abandonment_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abandonment_summary['total_abandoned_projects'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abandonment_summary['total_active_projects'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate abandonment rates for each milestone year\n",
    "for milestone in milestones:\n",
    "    abandonment_summary[f'abandoned_rate_{milestone}_years'] = (\n",
    "        abandonment_summary[f'abandoned_by_{milestone}_years'] / abandonment_summary['total_projects']\n",
    "    )\n",
    "\n",
    "for milestone in milestones:\n",
    "    abandonment_summary[f'abandoned_rate_{milestone}_years'] *= 100\n",
    "\n",
    "# Reorder columns for clarity\n",
    "rate_columns = [f'abandoned_rate_{milestone}_years' for milestone in milestones]\n",
    "cols = ['cohort_year', 'total_projects', 'total_abandoned_projects', 'total_active_projects'] + \\\n",
    "       sum([[f'abandoned_by_{milestone}_years', f'abandoned_rate_{milestone}_years', f'active_after_{milestone}_years'] for milestone in milestones], [])\n",
    "abandonment_summary = abandonment_summary[cols]\n",
    "\n",
    "# Display the updated DataFrame\n",
    "abandonment_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "# Define the milestones you're interested in\n",
    "milestones = [0, 1, 2, 3]  # Adjust this list if you have different milestones\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot the abandonment rates for each milestone\n",
    "for milestone in milestones:\n",
    "    plt.plot(\n",
    "        abandonment_summary['cohort_year'],\n",
    "        abandonment_summary[f'abandoned_rate_{milestone}_years'],\n",
    "        marker='o',\n",
    "        label=f'Abandoned after {milestone} Year(s)'\n",
    "    )\n",
    "\n",
    "# Set plot title and labels\n",
    "plt.title('Abandonment Rate Trend Over Cohort Years')\n",
    "plt.xlabel('Cohort Year')\n",
    "plt.ylabel('Abandonment Rate')\n",
    "\n",
    "# Format the y-axis as percentages\n",
    "plt.gca().yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "\n",
    "# Add grid for better readability\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# Add legend\n",
    "plt.legend(title='Milestone Years')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
