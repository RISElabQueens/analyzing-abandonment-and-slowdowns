{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ab = pd.read_csv('active_projects_with_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter artifacts with more than 4 releases\n",
    "data = data_ab.groupby('artifact_id').filter(lambda x: len(x) > 4)\n",
    "\n",
    "data['release_timestamp'] = pd.to_datetime(data['release_timestamp'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['artifact_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data by artifact_id and release_timestamp\n",
    "data = data.sort_values(by=['artifact_id', 'release_timestamp'])\n",
    "\n",
    "# Calculate time intervals in days\n",
    "data['time_gap'] = data.groupby('artifact_id')['release_timestamp'].diff().dt.total_seconds() / (60 * 60 * 24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_artifact(group):\n",
    "    # Calculate project start and end timestamps\n",
    "    project_start = group['release_timestamp'].min()\n",
    "    project_end = group['release_timestamp'].max()\n",
    "\n",
    "    # Calculate total duration in days\n",
    "    total_duration = (project_end - project_start).total_seconds() / (60 * 60 * 24)\n",
    "\n",
    "    # Calculate cumulative progress as a fraction of total duration\n",
    "    group['cumulative_progress'] = (\n",
    "        (group['release_timestamp'] - project_start).dt.total_seconds() / (60 * 60 * 24)\n",
    "    ) / total_duration\n",
    "\n",
    "    # Assign quartiles based on cumulative progress\n",
    "    group['Quartile'] = pd.cut(\n",
    "        group['cumulative_progress'],\n",
    "        bins=[0, 0.25, 0.5, 0.75, 1],\n",
    "        labels=['Q1', 'Q2', 'Q3', 'Q4'],\n",
    "        include_lowest=True\n",
    "    )\n",
    "\n",
    "    # Calculate time intervals to the next release\n",
    "    group['time_to_next_release'] = group['release_timestamp'].shift(-1) - group['release_timestamp']\n",
    "    group['time_to_next_release'] = group['time_to_next_release'].dt.total_seconds() / (60 * 60 * 24)\n",
    "\n",
    "    # Replace NaN (last release) with 0\n",
    "    # group['time_to_next_release'] = group[group['time_to_next_release']].notna()\n",
    "    # print(group)\n",
    "    group = group[group['time_to_next_release'].notna()]\n",
    "\n",
    "    # Calculate average time intervals within each quartile\n",
    "    average_intervals = group.groupby('Quartile')['time_to_next_release'].mean()\n",
    "\n",
    "    # Calculate mean and standard deviation of time intervals\n",
    "    mean_interval = group['time_to_next_release'].mean()\n",
    "    std_dev_interval = group['time_to_next_release'].std()\n",
    "\n",
    "    # Define thresholds for \"Fast,\" \"Normal,\" and \"Slow\"\n",
    "    # fast_threshold = mean_interval - 2 * std_dev_interval\n",
    "    # slow_threshold = mean_interval + 2 * std_dev_interval\n",
    "    fast_threshold = 0.8 * mean_interval\n",
    "    slow_threshold = 1.2 * mean_interval\n",
    "\n",
    "    # Assign \"Fast,\" \"Normal,\" or \"Slow\" labels based on thresholds\n",
    "    quartile_labels = average_intervals.apply(\n",
    "        lambda x: 'Fast' if x < fast_threshold else \n",
    "                  ('Slow' if x > slow_threshold else 'Normal')\n",
    "    )\n",
    "\n",
    "    # Map quartile labels back to group\n",
    "    group['Quartile_Label'] = group['Quartile'].map(quartile_labels.to_dict())\n",
    "\n",
    "    return group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandarallel import pandarallel\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Initialize pandarallel\n",
    "pandarallel.initialize(progress_bar=True, verbose=1)  # Enable progress bar and verbosity\n",
    "\n",
    "# Apply the function in parallel\n",
    "result = data.groupby('artifact_id').parallel_apply(analyze_artifact)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index to make the DataFrame clean\n",
    "result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Select relevant columns for final output\n",
    "final_df = result[['artifact_id', 'release_timestamp', 'cumulative_progress', 'Quartile', 'time_to_next_release', 'Quartile_Label']]\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by artifact_id and Quartile to calculate average time intervals and labels\n",
    "\n",
    "quartile_summary = result.groupby(['artifact_id', 'Quartile']).agg(\n",
    "    avg_time_interval=('time_to_next_release', 'mean'),\n",
    "    quartile_label=('Quartile_Label', 'first')  # Assuming consistency within a quartile\n",
    ").reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the DataFrame so that each Quartile becomes a column\n",
    "pivoted_df = quartile_summary.pivot(\n",
    "    index='artifact_id',\n",
    "    columns='Quartile',\n",
    "    values=['avg_time_interval', 'quartile_label']\n",
    ")\n",
    "\n",
    "# Flatten MultiIndex columns for better readability\n",
    "pivoted_df.columns = [f\"{stat}_{quartile}\" for stat, quartile in pivoted_df.columns]\n",
    "\n",
    "# Reset index for a clean DataFrame\n",
    "pivoted_df.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column summarizing the quartile labels in order\n",
    "pivoted_df['quartile_label_summary'] = pivoted_df.apply(\n",
    "    lambda row: f\"Q1: {row['quartile_label_Q1']} > Q2: {row['quartile_label_Q2']} > Q3: {row['quartile_label_Q3']} > Q4: {row['quartile_label_Q4']}\",\n",
    "    axis=1\n",
    ")\n",
    "pivoted_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column summarizing the quartile labels in order\n",
    "pivoted_df['quartile_label_summary'] = pivoted_df.apply(\n",
    "    lambda row: f\"{row['quartile_label_Q1']} > {row['quartile_label_Q2']} > {row['quartile_label_Q3']} > {row['quartile_label_Q4']}\",\n",
    "    axis=1\n",
    ")\n",
    "pivoted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted_df['quartile_label_summary'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10 = pivoted_df['quartile_label_summary'].value_counts(normalize=True).head(10)\n",
    "print(top_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stopped here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10 = pivoted_df['quartile_label_summary'].value_counts(normalize=False).head(10)\n",
    "top_10_normalized = pivoted_df['quartile_label_summary'].value_counts(normalize=True).head(10) * 100\n",
    "\n",
    "# Combine both counts and proportions into a single DataFrame\n",
    "top_10_combined = pd.DataFrame({\n",
    "    'Count': top_10,\n",
    "    'Proportion': top_10_normalized\n",
    "})\n",
    "\n",
    "print(top_10_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the top 10 patterns\n",
    "top_10_patterns = top_10_combined.index\n",
    "\n",
    "# Filter the pivoted DataFrame for the top 10 patterns\n",
    "top_10_df = pivoted_df[pivoted_df['quartile_label_summary'].isin(top_10_patterns)]\n",
    "\n",
    "# Calculate the release count per artifact\n",
    "release_count_stats = data.groupby('artifact_id').size().reset_index(name='release_count')\n",
    "\n",
    "# Merge the release count with the filtered top 10 patterns\n",
    "top_10_with_counts = top_10_df.merge(release_count_stats, on='artifact_id', how='left')\n",
    "\n",
    "# Group by quartile_label_summary and calculate the min and max release counts\n",
    "top_10_release_count_range = top_10_with_counts.groupby('quartile_label_summary')['release_count'].agg(['min', 'max']).reset_index()\n",
    "\n",
    "# Merge the range with the original top_10_combined DataFrame for a full summary\n",
    "top_10_combined_with_range = top_10_combined.merge(\n",
    "    top_10_release_count_range, \n",
    "    left_index=True, \n",
    "    right_on='quartile_label_summary'\n",
    ")\n",
    "\n",
    "# Rename columns for clarity\n",
    "top_10_combined_with_range.rename(columns={'min': 'Min Release Count', 'max': 'Max Release Count'}, inplace=True)\n",
    "\n",
    "# Display the final result\n",
    "top_10_combined_with_range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by quartile_label_summary and calculate min, max, mean, and median release counts\n",
    "top_10_release_count_stats = top_10_with_counts.groupby('quartile_label_summary')['release_count'].agg(['min', 'mean', 'median','max']).reset_index()\n",
    "\n",
    "# Merge the stats with the original top_10_combined DataFrame for a full summary\n",
    "top_10_combined_with_stats = top_10_combined.merge(\n",
    "    top_10_release_count_stats, \n",
    "    left_index=True, \n",
    "    right_on='quartile_label_summary'\n",
    ")\n",
    "\n",
    "# Rename columns for clarity\n",
    "top_10_combined_with_stats.rename(\n",
    "    columns={\n",
    "        'min': 'Min Release Count', \n",
    "        'mean': 'Mean Release Count',\n",
    "        'median': 'Median Release Count',\n",
    "        'max': 'Max Release Count',\n",
    "    }, \n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "# Display the final result\n",
    "top_10_combined_with_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivoted_df['quartile_label_summary'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate absolute counts\n",
    "counts = pivoted_df['quartile_label_summary'].value_counts()\n",
    "\n",
    "# Calculate percentages\n",
    "percentages = pivoted_df['quartile_label_summary'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Combine counts and percentages into a single DataFrame\n",
    "summary = pd.DataFrame({\n",
    "    'Count': counts,\n",
    "    'Percentage (%)': percentages\n",
    "})\n",
    "\n",
    "# Display the result\n",
    "summary\n",
    "\n",
    "#active projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the desired quartile label pattern\n",
    "desired_pattern = \"Normal > Normal > nan > Normal\"\n",
    "\n",
    "# Filter the DataFrame based on the quartile_label_summary column\n",
    "matching_artifacts = pivoted_df[pivoted_df['quartile_label_summary'] == desired_pattern]\n",
    "print(matching_artifacts[['artifact_id', 'quartile_label_summary']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
